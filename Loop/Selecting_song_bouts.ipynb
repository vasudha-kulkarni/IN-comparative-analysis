{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loops over all files and cuts up the whole file into song bouts, so they can be filtered based on different criteria.\n",
    "09/11/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas\n",
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from math import nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'motif_finder_unisyl' filters song bouts based on the number of unique syllables in that bout. Currently, it removes bouts with 3 or less unique notes per bout (5 including 'Start' and 'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the indices of all the occurrence of 'End' in Syllable label\n",
    "def find_end_indices(list, element):\n",
    "    indices = [0]\n",
    "    for idx, value in enumerate(list):\n",
    "        if value == element:\n",
    "            indices.append(idx)\n",
    "    return indices\n",
    "\n",
    "#Define a function to pick song bouts that are long in length\n",
    "#Returns a list of data frames\n",
    "def motif_finder(bouts_list):\n",
    "    song_w_motif = bouts_list.copy()\n",
    "    syll_num = []\n",
    "    short_song_idx = []\n",
    "    for i in range(len(bouts_list)):\n",
    "        bout = bouts_list[i]\n",
    "        syllable_list = bout['Syll Label'].tolist()\n",
    "        syll_num.append(len(syllable_list))\n",
    "    avg_syl_num = np.mean(syll_num)\n",
    "    for i in range(len(syll_num)):\n",
    "        if syll_num[i] < avg_syl_num/3:\n",
    "            short_song_idx.append(i)\n",
    "    #as each index is deleted, the list shortens, so indices have to be updated\n",
    "    for i in range(len(short_song_idx)):\n",
    "        short_song_idx[i] -= i\n",
    "    for j in short_song_idx:\n",
    "        del song_w_motif[j]\n",
    "    return song_w_motif\n",
    "\n",
    "#Define a function to pick song bouts that more than 3 unique syllables in the bout\n",
    "#Returns a list of data frames\n",
    "def motif_finder_unisyl(bouts_list):\n",
    "    song_w_motif = bouts_list.copy()\n",
    "    uni_syll_num = []\n",
    "    short_song_idx = []\n",
    "    for i in range(len(bouts_list)):\n",
    "        bout = bouts_list[i]\n",
    "        syl_n = bout['Syll Label'].value_counts()\n",
    "        uni_syll_num.append(len(syl_n))\n",
    "    #print(uni_syll_num)\n",
    "    for i in range(len(uni_syll_num)):\n",
    "        #Start, End, 3 unique syllables = 5\n",
    "        #Any bout with only 3 unique syllables should be removed as a call bout\n",
    "        if uni_syll_num[i] < 6:\n",
    "            short_song_idx.append(i)\n",
    "    #as each index is deleted, the list shortens, so indices have to be updated\n",
    "    for i in range(len(short_song_idx)):\n",
    "        short_song_idx[i] -= i\n",
    "    for j in short_song_idx:\n",
    "        del song_w_motif[j]\n",
    "    return song_w_motif\n",
    "\n",
    "#Combines all the dataframes in a list\n",
    "def concatenate_bout_list(bout_list):\n",
    "    new_df = pandas.DataFrame()\n",
    "    for i in range(len(bout_list)):\n",
    "        new_df = pandas.concat([new_df, bout_list[i]])\n",
    "    start_row = [0, 0, 'Start', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    new_df = pandas.DataFrame(np.insert(new_df.values, 0, start_row, axis=0))\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\Loop\\\\Start_End'\n",
    "\n",
    "start_end_files = []\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.scandir(directory):\n",
    "    if filename.is_file():\n",
    "        start_end_files.append(filename.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['BCC_M01', 'BCC_M03', 'BCC_M08', 'BCC_M09', 'BCC_M11', 'BCC_M19', 'BCC_M21', 'BCC_M22', \n",
    "    'BF_brn24pnk13', 'BF_brn25pnk14', 'BF_brn35pnk21', 'BF_brn36pnk24', 'BF_org27ylw19',\n",
    "    'JF_red28blu13', 'JF_ylw14gry00', 'JF_ylw20gry09', 'JF_ylw22gry08', 'JF_ylw25gry11',\n",
    "    'ZF_grn21org41', 'ZF_org01wht58', 'ZF_org11pnk05', 'ZF_pnk93pnk91', 'ZF_red15ylw15', 'ZF_red77pnk45', 'ZF_ylw67brn42', 'ZF_ylw95ylw29']\n",
    "\n",
    "sp_label = ['BCC', 'BCC', 'BCC', 'BCC', 'BCC', 'BCC', 'BCC', 'BCC', \n",
    "    'BF', 'BF', 'BF', 'BF', 'BF', \n",
    "    'JF', 'JF', 'JF', 'JF', 'JF',\n",
    "    'ZF', 'ZF', 'ZF', 'ZF', 'ZF', 'ZF', 'ZF', 'ZF', ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['ASB_Blackblue', 'ASB_orange', 'ASB_red', 'ASB_white', 'ASB_y36a', 'ASB_yellow',\n",
    "          'BCC_M01', 'BCC_M03', 'BCC_M08', 'BCC_M09', 'BCC_M11', 'BCC_M19', 'BCC_M21', 'BCC_M22',\n",
    "          'BF_brn20pnk9', 'BF_brn24pnk13', 'BF_brn25pnk14', 'BF_brn35pnk21', 'BF_brn36pnk24', 'BF_org20ylw24', 'BF_org27ylw19',\n",
    "          'ISB_r5y81', 'ISB_y51i', 'ISB_y54i', 'ISB_y61i', 'ISB_y63i',\n",
    "          'JF_red28blu13', 'JF_y23g09', 'JF_ylw14gry00', 'JF_ylw20gry09', 'JF_ylw22gry08', 'JF_ylw25gry11',\n",
    "          'SF_y08s', 'SF_y14s', 'SF_y47s', 'SF_y50s',\n",
    "          'ZF_grn21org41', 'ZF_org01wht58', 'ZF_org11pnk05', 'ZF_pnk93pnk91', 'ZF_red15ylw15', 'ZF_red77pnk45', 'ZF_ylw67brn42', 'ZF_ylw95ylw29']\n",
    "\n",
    "sp_label = ['ASB', 'ASB', 'ASB', 'ASB', 'ASB', 'ASB',\n",
    "            'BCC', 'BCC', 'BCC', 'BCC', 'BCC', 'BCC', 'BCC', 'BCC',\n",
    "            'BF', 'BF', 'BF', 'BF', 'BF', 'BF', 'BF',\n",
    "            'ISB', 'ISB', 'ISB', 'ISB', 'ISB',\n",
    "            'JF', 'JF', 'JF', 'JF', 'JF', 'JF',\n",
    "            'SF', 'SF', 'SF', 'SF',\n",
    "            'ZF', 'ZF', 'ZF', 'ZF', 'ZF', 'ZF', 'ZF', 'ZF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_sb = 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\Loop\\\\temp\\\\'\n",
    "\n",
    "for file_idx in range(len(start_end_files)):\n",
    "    data = pandas.read_csv(start_end_files[file_idx], header=None,\n",
    "        names = ['FileName', 'Syll #', 'Syll Label',\n",
    "        ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "        ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "        'AmplitudeModulation', 'EntropyVariance', 'Fundamental Frequency (Hz)', 'RMS Amplitude'])\n",
    "    \n",
    "    syl = data['Syll Label']\n",
    "    all_syl = syl.tolist()\n",
    "    end_indices = find_end_indices(all_syl, 'End')\n",
    "\n",
    "    song_bouts = []\n",
    "    #This method of slicing includes 'Start' and 'End'\n",
    "    for i in range(len(end_indices)-1):\n",
    "        x = data.iloc[end_indices[i] + 1 : end_indices[i+1] + 1, :]\n",
    "        song_bouts.append(x)\n",
    "\n",
    "    song_motif = motif_finder_unisyl(song_bouts)\n",
    "\n",
    "    motif_bouts = concatenate_bout_list(song_motif)\n",
    "    motif_bouts.columns = ['FileName', 'Syll #', 'Syll Label',\n",
    "      ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "      ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "      'AmplitudeModulation', 'EntropyVariance', 'Fundamental Frequency (Hz)', 'RMS Amplitude']\n",
    "\n",
    "    fname_sb = save_dir_sb + labels[file_idx] + '_bout2_start_end.csv'\n",
    "    motif_bouts.to_csv(fname_sb, header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate everything for those files with song motifs (song bouts with sufficiently high number of unoque syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\Loop\\\\temp'\n",
    "\n",
    "song_bout_files = []\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.scandir(directory):\n",
    "    if filename.is_file():\n",
    "        song_bout_files.append(filename.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_bout_tp = 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\Loop\\\\temp\\\\'\n",
    "\n",
    "for file_idx in range(len(song_bout_files)):\n",
    "   data = pandas.read_csv(song_bout_files[file_idx], header=None,\n",
    "      names = ['FileName', 'Syll #', 'Syll Label',\n",
    "      ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "      ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "      'AmplitudeModulation', 'EntropyVariance', 'Fundamental Frequency (Hz)', 'RMS Amplitude'])\n",
    "\n",
    "   syl = data['Syll Label']\n",
    "   #Get the set of unique syllables for the individual with their own index (so convert array to list)\n",
    "   uniq_syl = syl.unique()\n",
    "   uniq_syl = uniq_syl.tolist()\n",
    "   #Get the number of syllables to create a N x N matrix for transition\n",
    "   N = len(uniq_syl)\n",
    "   trans_matrix = np.array(np.zeros((N, N), dtype = int))\n",
    "   #Convert 'object' type to array to get indices\n",
    "   syl = np.array(syl)\n",
    "   #This gives the number of syllable transitions\n",
    "   for i in range(len(syl)-1):\n",
    "      a = uniq_syl.index(syl[i])\n",
    "      b = uniq_syl.index(syl[i+1])\n",
    "      trans_matrix[a, b] += 1\n",
    "   #Divide by total number of transitions\n",
    "   trans_matrix = (trans_matrix.T/trans_matrix.sum(axis=1)).T\n",
    "   trans_matrix = np.around(trans_matrix, 2)\n",
    "   \n",
    "   #To remove values less than 0.05 \n",
    "   for i in range(len(trans_matrix)):\n",
    "      for j in range(len(trans_matrix)):\n",
    "         if trans_matrix[i, j] < 0.05:\n",
    "            trans_matrix[i, j] = 0\n",
    "   #Add the labels of syllables as an extra row and column\n",
    "   syl_name = np.array(uniq_syl)\n",
    "   trans_prob = np.concatenate([[syl_name], trans_matrix])\n",
    "\n",
    "   #Add a '0' in the beginning to insert this as a column\n",
    "   syl_name = np.concatenate([[0], syl_name])\n",
    "   trans_prob = np.insert(trans_prob, 0, syl_name, axis = 1)\n",
    "\n",
    "   transition_probability = pandas.DataFrame(trans_prob)\n",
    "   fname_tp = save_dir_bout_tp + labels[file_idx] + '_bout2_trans_prob.csv'\n",
    "   transition_probability.to_csv(fname_tp, header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating quantifiers from syllable transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\Loop\\\\Bout_trans_prob_processed'\n",
    "\n",
    "bout_tp_files = []\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.scandir(directory):\n",
    "    if filename.is_file():\n",
    "        bout_tp_files.append(filename.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Bird name' : [],\n",
    "    'Species' : [],\n",
    "    'No. of Unique Syllables' : [],\n",
    "    'Sequence Linearity' : [],\n",
    "    'Sequence Consistency' : [],\n",
    "    'Sequence stereotypy' : [],\n",
    "    'Transition Entropy' : [],\n",
    "    'No. of Unique Start Syll' : [],\n",
    "    'Fraction of Unique Start Syll' : [],\n",
    "    'No. of Unique transitions' : []\n",
    "}\n",
    "\n",
    "df = pandas.DataFrame(data)\n",
    "\n",
    "df.to_csv('01. Song_quantifiers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VASUDH~1\\AppData\\Local\\Temp/ipykernel_20028/1479874747.py:40: RuntimeWarning: divide by zero encountered in log2\n",
      "  trans_entropy[i, j] = -trans_entropy[i, j] * np.log2(trans_entropy[i, j])\n",
      "C:\\Users\\VASUDH~1\\AppData\\Local\\Temp/ipykernel_20028/1479874747.py:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  trans_entropy[i, j] = -trans_entropy[i, j] * np.log2(trans_entropy[i, j])\n"
     ]
    }
   ],
   "source": [
    "#From the song-motif transition probability, this code calculates sequence linearity, consistency, stereotypy, \n",
    "#transition entropy and the number of initial starting syllables\n",
    "\n",
    "for file_idx in range(len(bout_tp_files)):\n",
    "    file = pandas.read_csv(bout_tp_files[file_idx], header=None)\n",
    "    #Drop the row and column labels, just keep the numeric values\n",
    "    trans_prob = file.iloc[1:, 1:]\n",
    "    trans_prob = np.array(trans_prob)\n",
    "    trans_prob = trans_prob.astype(float)\n",
    "\n",
    "    #Get the set of unique syllables for the individual with their own index (so convert array to list)\n",
    "    uniq_syl = file.iloc[0].to_numpy()\n",
    "    uniq_syl = np.delete(uniq_syl, 0)\n",
    "\n",
    "    #SEQUENCE LINEARITY\n",
    "    #Number of unique syllables\n",
    "    n_syl = len(uniq_syl)\n",
    "    #To get the number of unique transitions, create an array with 1 whenever trans_prob > 0\n",
    "    #and get the sum of the array\n",
    "    trans_num = np.zeros_like(trans_prob)\n",
    "    trans_num[trans_prob > 0] = 1\n",
    "    n_trans = sum(map(sum, trans_num))\n",
    "    s_lin = n_syl/n_trans\n",
    "\n",
    "    #SEQUENCE CONSISTENCY\n",
    "    #numerator - sum of typical transitions\n",
    "    typ_trans = np.max(trans_prob, axis = 1)\n",
    "    typ_sum = sum(typ_trans)\n",
    "    #denominator - sum of all transitions\n",
    "    trans_sum = sum(map(sum, trans_prob))\n",
    "    s_con = typ_sum/trans_sum\n",
    "\n",
    "    #SEQUENCE STEREOTYPY\n",
    "    s_stereo = (s_lin + s_con)/2\n",
    "\n",
    "    #TRANSITION ENTROPY\n",
    "    trans_entropy = trans_prob\n",
    "    for i in range(len(trans_entropy)):\n",
    "        for j in range(len(trans_entropy)):\n",
    "            trans_entropy[i, j] = -trans_entropy[i, j] * np.log2(trans_entropy[i, j])\n",
    "    trans_entropy[np.isnan(trans_entropy)] = 0\n",
    "    transition_entropy = sum(map(sum, trans_entropy))\n",
    "\n",
    "    #To get the number of transitions from 'Start'\n",
    "    syl_list = uniq_syl.tolist()\n",
    "    s = syl_list.index('Start') #get the idex of 'Start' row\n",
    "    #sum over Number of transitions matrix 'Start' row using the index\n",
    "    n_start = np.sum(trans_num[s])\n",
    "\n",
    "    data = {\n",
    "    'Bird name' : [labels[file_idx]],\n",
    "    'Species' : [sp_label[file_idx]],\n",
    "    'No. of Unique Syllables' : [n_syl],\n",
    "    'Sequence Linearity' : [s_lin],\n",
    "    'Sequence Consistency' : [s_con],\n",
    "    'Sequence stereotypy' : [s_stereo],\n",
    "    'Transition Entropy' : [transition_entropy],\n",
    "    'No. of Unique Start Syll' : [n_start],\n",
    "    'Fraction of Unique Start Syll' : [n_start/n_syl],\n",
    "    'No. of Unique transitions' : [n_trans]\n",
    "    }\n",
    "    df = pandas.DataFrame(data)\n",
    "\n",
    "    df.to_csv('01. Song_quantifiers.csv', mode = 'a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "008563563e781916d6359c24295d5508987d9d4a8f497f916ed83e23a440f2f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
