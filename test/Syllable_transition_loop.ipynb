{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file has the code to obtain syllable transition values from Onset-Offset data, and process the file\n",
    "\n",
    "Date: 20/9/2022\n",
    "\n",
    "Problems:\n",
    "1. Bouts are picked if gap > 2s and when there's a change in filename - should be modified if songbouts are cut up across files (BCC)\n",
    "2. Rare/esoteric syllables have not been removed\n",
    "3. 'End' -> 'Start' transition probability value is 1 in the output file. This needs to be changed when processing the Trans_prob file.\n",
    "\n",
    "Major changes in ZF OnsetOffsetFiles - \n",
    "15 columns, instead of 13. So, ['Fundamental Frequency (Hz)', 'RMS Amplitude'] added at the end. Start and End row modified by adding two extra zeroes. Works for all other files as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign directory\n",
    "directory = 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\test\\\\temp'\n",
    "\n",
    "onset_files = []\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.scandir(directory):\n",
    "    if filename.is_file():\n",
    "        onset_files.append(filename.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directories to save Start_end and Trans_prob files\n",
    "save_dir_se = 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\test\\\\temp\\\\'\n",
    "save_dir_tp = 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\test\\\\temp\\\\'\n",
    "\n",
    "# labels = ['BCC_M01', 'BCC_M03', 'BCC_M08', 'BCC_M09', 'BCC_M11', 'BCC_M19', 'BCC_M21', 'BCC_M22', 'BF_brn24pnk13', ]\n",
    "# sp_label = ['BCC', 'BCC', 'BCC', 'BCC', 'BCC', 'BCC', 'BCC', 'BCC', 'BF']\n",
    "\n",
    "labels = ['BF_brn24pnk13']\n",
    "sp_label = ['BF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates Start-End files from OnsetOffset files\n",
    "for file_idx in range(len(onset_files)):\n",
    "   data = pandas.read_csv(onset_files[file_idx], sep = '\\t', header=None, \n",
    "      names = ['FileName', 'Syll #', 'Syll Label',\n",
    "      ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "      ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "      'AmplitudeModulation', 'EntropyVariance', 'Fundamental Frequency (Hz)', 'RMS Amplitude'])\n",
    "   #Drop the first row\n",
    "   data = data.iloc[1:, :]\n",
    "   #Convert onset, offset and syllable duration to float type\n",
    "   data[' Syll Onset (ms)'] = data[' Syll Onset (ms)'].astype(float)\n",
    "   data[' Syll Offset (ms)'] = data[' Syll Offset (ms)'].astype(float)\n",
    "   data[' Syll Duration (sec)'] = data[' Syll Duration (sec)'].astype(float)\n",
    "   \n",
    "   #Add a 'start' label in the beginning of the dataframe\n",
    "   start_row = [0, 0, 'Start', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "   data = pandas.DataFrame(np.insert(data.values, 0, start_row, axis=0))\n",
    "   #Give column labels again\n",
    "   data.columns = ['FileName', 'Syll #', 'Syll Label',\n",
    "      ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "      ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "      'AmplitudeModulation', 'EntropyVariance', 'Fundamental Frequency (Hz)', 'RMS Amplitude']\n",
    "   \n",
    "   #To add a 'start' and 'end' in syllable label column after end of every bout\n",
    "   t_offset = data[' Syll Offset (ms)']\n",
    "   new_row = [[0, 0, 'End', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 'Start', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "   \n",
    "   #Create a list of indices where the labels should be inserted - gap > 2s or in between files\n",
    "   index_list_bout = []\n",
    "   for i in range(1, len(data)-1):\n",
    "      diff = t_offset[i+1] - t_offset[i]\n",
    "      if diff > 2000:\n",
    "         index_list_bout.append(i)\n",
    "   #print(index_list_bout)\n",
    "   #Adjust the index to correct for where the row will be inserted\n",
    "   for j in range(len(index_list_bout)):\n",
    "      index_list_bout[j] += (2*j + 1)\n",
    "   for k in index_list_bout:\n",
    "      data = pandas.DataFrame(np.insert(data.values, k, new_row, axis=0))\n",
    "   \n",
    "   #Give column labels again\n",
    "   data.columns = ['FileName', 'Syll #', 'Syll Label',\n",
    "      ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "      ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "      'AmplitudeModulation', 'EntropyVariance', 'Fundamental Frequency (Hz)', 'RMS Amplitude']\n",
    "   \n",
    "   syll_idx = data['Syll #']\n",
    "   index_list_file = []\n",
    "   for i in range(1, len(data)-1):\n",
    "      if syll_idx[i] == '1':\n",
    "         index_list_file.append(i)\n",
    "   #print(len(index_list_file))\n",
    "   #'end-start' rows need to be inserted one step before data from new file begins\n",
    "   ones = np.ones(len(index_list_file))\n",
    "   index_list_file = index_list_file - ones\n",
    "   #delete first index - to ignore the first \"new\" file\n",
    "   index_list_file = index_list_file[1:]\n",
    "   index_list_file = index_list_file.astype(int)\n",
    "\n",
    "   for l in range(len(index_list_file)):\n",
    "      index_list_file[l] += (2*l + 1)\n",
    "   #Insert the new_row at these indices\n",
    "   #PS. If this doesn't make sense, remove the correction, do a simple FOR loop and see what happens\n",
    "   for m in index_list_file:\n",
    "      data = pandas.DataFrame(np.insert(data.values, m, new_row, axis=0))\n",
    "\n",
    "   #To add an 'End' label at the end\n",
    "   end_row = [[0, 0, 'End', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "   data = pandas.DataFrame(np.insert(data.values, len(data), end_row, axis=0))\n",
    "   \n",
    "   #Give column labels again\n",
    "   data.columns = ['FileName', 'Syll #', 'Syll Label',\n",
    "      ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "      ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "      'AmplitudeModulation', 'EntropyVariance', 'Fundamental Frequency (Hz)', 'RMS Amplitude']\n",
    "   \n",
    "   fname_se = save_dir_se + labels[file_idx] + '_start_end.csv'\n",
    "   data.to_csv(fname_se, header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\test\\\\temp'\n",
    "\n",
    "start_end_files = []\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.scandir(directory):\n",
    "    if filename.is_file():\n",
    "        start_end_files.append(filename.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For creating trans_prob files\n",
    "\n",
    "#labels = ['JF_red28blu13', 'JF_ylw25gry11']\n",
    "\n",
    "for file_idx in range(len(start_end_files)):\n",
    "   data = pandas.read_csv(start_end_files[file_idx], header = None, \n",
    "      names = ['FileName', 'Syll #', 'Syll Label',\n",
    "      ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "      ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "      'AmplitudeModulation', 'EntropyVariance', 'Fundamental Frequency (Hz)', 'RMS Amplitude'])\n",
    "   syl = data['Syll Label']\n",
    "   #print(syl)\n",
    "   #Get the set of unique syllables for the individual with their own index (so convert array to list)\n",
    "   uniq_syl = syl.unique()\n",
    "   uniq_syl = uniq_syl.tolist()\n",
    "   #print(uniq_syl)\n",
    "   #Get the number of syllables to create a N x N matrix for transition\n",
    "   N = len(uniq_syl)\n",
    "   trans_matrix = np.array(np.zeros((N, N), dtype = int))\n",
    "   #Convert 'object' type to array to get indices\n",
    "   syl = np.array(syl)\n",
    "   #This gives the number of syllable transitions\n",
    "   for i in range(len(syl)-1):\n",
    "      a = uniq_syl.index(syl[i])\n",
    "      b = uniq_syl.index(syl[i+1])\n",
    "      trans_matrix[a, b] += 1\n",
    "   #Divide by total number of transitions\n",
    "   trans_matrix = (trans_matrix.T/trans_matrix.sum(axis=1)).T\n",
    "   trans_matrix = np.around(trans_matrix, 2)\n",
    "   \n",
    "   #To remove values less than 0.05 \n",
    "   for i in range(len(trans_matrix)):\n",
    "      for j in range(len(trans_matrix)):\n",
    "         if trans_matrix[i, j] < 0.05:\n",
    "            trans_matrix[i, j] = 0\n",
    "   #Add the labels of syllables as an extra row and column\n",
    "   syl_name = np.array(uniq_syl)\n",
    "   trans_prob = np.concatenate([[syl_name], trans_matrix])\n",
    "\n",
    "   #Add a '0' in the beginning to insert this as a column\n",
    "   syl_name = np.concatenate([[0], syl_name])\n",
    "   trans_prob = np.insert(trans_prob, 0, syl_name, axis = 1)\n",
    "\n",
    "   transition_probability = pandas.DataFrame(trans_prob)\n",
    "   fname_tp = save_dir_tp + labels[file_idx] + '_transition_probability.csv'\n",
    "   transition_probability.to_csv(fname_tp, header = False, index = False)\n",
    "\n",
    "#Remember: Delete End->Start = 1 value from the file\n",
    "#This file contains the low-occuring syllables as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\4th Year\\Semester 7\\BI4313 Sem Project\\IN-comparative-analysis\\IN-comparative-analysis\\test\\temp\\BF_brn24pnk13_start_end.csv\n",
      "Series([], Name: Syll Label, dtype: int64)\n",
      "0\n",
      "D:\\4th Year\\Semester 7\\BI4313 Sem Project\\IN-comparative-analysis\\IN-comparative-analysis\\test\\temp\\BF_brn24pnk13_transition_probability.csv\n",
      "Series([], Name: Syll Label, dtype: int64)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#To get the occurrence of number of syllables\n",
    "#And confirm that this is the same as row_sum of trans_matrix\n",
    "for file_idx in range(len(onset_files)):\n",
    "    data = pandas.read_csv(onset_files[file_idx], sep = '\\t', header=None, \n",
    "      names = ['FileName', 'Syll #', 'Syll Label',\n",
    "      ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "      ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "      'AmplitudeModulation', 'EntropyVariance', 'Fundamental Frequency (Hz)', 'RMS Amplitude'])\n",
    "    syl_n = data['Syll Label'].value_counts()\n",
    "    print(onset_files[file_idx])\n",
    "    print(syl_n) \n",
    "    print(len(syl_n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "008563563e781916d6359c24295d5508987d9d4a8f497f916ed83e23a440f2f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
