{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loops over all files and cuts up the whole file into song bouts, so they can be filtered based on different criteria.\n",
    "09/11/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas\n",
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the indices of all the occurrence of 'End' in Syllable label\n",
    "def find_end_indices(list, element):\n",
    "    indices = [0]\n",
    "    for idx, value in enumerate(list):\n",
    "        if value == element:\n",
    "            indices.append(idx)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to pick song bouts that are long in length\n",
    "#Returns a list of data frames\n",
    "\n",
    "def motif_finder(bouts_list):\n",
    "    song_w_motif = bouts_list.copy()\n",
    "    syll_num = []\n",
    "    short_song_idx = []\n",
    "    for i in range(len(bouts_list)):\n",
    "        bout = bouts_list[i]\n",
    "        syllable_list = bout['Syll Label'].tolist()\n",
    "        syll_num.append(len(syllable_list))\n",
    "    avg_syl_num = np.mean(syll_num)\n",
    "    for i in range(len(syll_num)):\n",
    "        if syll_num[i] < avg_syl_num/3:\n",
    "            short_song_idx.append(i)\n",
    "    #as each index is deleted, the list shortens, so indices have to be updated\n",
    "    for i in range(len(short_song_idx)):\n",
    "        short_song_idx[i] -= i\n",
    "    for j in short_song_idx:\n",
    "        del song_w_motif[j]\n",
    "    return song_w_motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combines all the dataframes in a list\n",
    "\n",
    "def concatenate_bout_list(bout_list):\n",
    "    new_df = pandas.DataFrame()\n",
    "    for i in range(len(bout_list)):\n",
    "        new_df = pandas.concat([new_df, bout_list[i]])\n",
    "    start_row = [0, 0, 'Start', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    new_df = pandas.DataFrame(np.insert(new_df.values, 0, start_row, axis=0))\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\test\\\\Start_End'\n",
    "\n",
    "onset_files = []\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.scandir(directory):\n",
    "    if filename.is_file():\n",
    "        onset_files.append(filename.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\test\\\\Start_End\\\\BCC_M01_start_end.csv',\n",
       " 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\test\\\\Start_End\\\\BCC_M03_start_end.csv',\n",
       " 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\test\\\\Start_End\\\\JF_ylw22gry08_start_end.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onset_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_sb = 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\test\\\\Bouts_Start_End\\\\'\n",
    "\n",
    "labels = ['BCC_M01', 'BCC_M03', 'JF_ylw22gry08']\n",
    "\n",
    "for file_idx in range(len(onset_files)):\n",
    "    data = pandas.read_csv(onset_files[file_idx], header=None,\n",
    "        names = ['FileName', 'Syll #', 'Syll Label',\n",
    "        ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "        ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "        'AmplitudeModulation', 'EntropyVariance', 'Fundamental Frequency (Hz)', 'RMS Amplitude'])\n",
    "    \n",
    "    syl = data['Syll Label']\n",
    "    all_syl = syl.tolist()\n",
    "    end_indices = find_end_indices(all_syl, 'End')\n",
    "\n",
    "    song_bouts = []\n",
    "    #This method of slicing includes 'Start' and 'End'\n",
    "    for i in range(len(end_indices)-1):\n",
    "        x = data.iloc[end_indices[i] + 1 : end_indices[i+1] + 1, :]\n",
    "        song_bouts.append(x)\n",
    "\n",
    "    song_motif = motif_finder(song_bouts)\n",
    "\n",
    "    motif_bouts = concatenate_bout_list(song_motif)\n",
    "    motif_bouts.columns = ['FileName', 'Syll #', 'Syll Label',\n",
    "      ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "      ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "      'AmplitudeModulation', 'EntropyVariance', 'Fundamental Frequency (Hz)', 'RMS Amplitude']\n",
    "\n",
    "    fname_sb = save_dir_sb + labels[file_idx] + '_bouts_start_end.csv'\n",
    "    motif_bouts.to_csv(fname_sb, header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate everything for those files with song motifs (song bouts with sufficiently high number of bouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\test\\\\Bouts_Start_End'\n",
    "\n",
    "song_bout_files = []\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.scandir(directory):\n",
    "    if filename.is_file():\n",
    "        song_bout_files.append(filename.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_tp = 'D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\test\\\\Trans_prob\\\\'\n",
    "\n",
    "for file_idx in range(len(song_bout_files)):\n",
    "   data = pandas.read_csv(song_bout_files[file_idx], header=None,\n",
    "      names = ['FileName', 'Syll #', 'Syll Label',\n",
    "      ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "      ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "      'AmplitudeModulation', 'EntropyVariance', 'Fundamental Frequency (Hz)', 'RMS Amplitude'])\n",
    "\n",
    "   syl = data['Syll Label']\n",
    "   #Get the set of unique syllables for the individual with their own index (so convert array to list)\n",
    "   uniq_syl = syl.unique()\n",
    "   uniq_syl = uniq_syl.tolist()\n",
    "   #Get the number of syllables to create a N x N matrix for transition\n",
    "   N = len(uniq_syl)\n",
    "   trans_matrix = np.array(np.zeros((N, N), dtype = int))\n",
    "   #Convert 'object' type to array to get indices\n",
    "   syl = np.array(syl)\n",
    "   #This gives the number of syllable transitions\n",
    "   for i in range(len(syl)-1):\n",
    "      a = uniq_syl.index(syl[i])\n",
    "      b = uniq_syl.index(syl[i+1])\n",
    "      trans_matrix[a, b] += 1\n",
    "   #Divide by total number of transitions\n",
    "   trans_matrix = (trans_matrix.T/trans_matrix.sum(axis=1)).T\n",
    "   trans_matrix = np.around(trans_matrix, 2)\n",
    "   \n",
    "   #To remove values less than 0.05 \n",
    "   for i in range(len(trans_matrix)):\n",
    "      for j in range(len(trans_matrix)):\n",
    "         if trans_matrix[i, j] < 0.05:\n",
    "            trans_matrix[i, j] = 0\n",
    "   #Add the labels of syllables as an extra row and column\n",
    "   syl_name = np.array(uniq_syl)\n",
    "   trans_prob = np.concatenate([[syl_name], trans_matrix])\n",
    "\n",
    "   #Add a '0' in the beginning to insert this as a column\n",
    "   syl_name = np.concatenate([[0], syl_name])\n",
    "   trans_prob = np.insert(trans_prob, 0, syl_name, axis = 1)\n",
    "\n",
    "   transition_probability = pandas.DataFrame(trans_prob)\n",
    "   fname_tp = save_dir_tp + labels[file_idx] + '_bout_trans_prob.csv'\n",
    "   transition_probability.to_csv(fname_tp, header = False, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "008563563e781916d6359c24295d5508987d9d4a8f497f916ed83e23a440f2f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
