{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains code to quantify differences in song structure and sequence based on sequence linearity, consistency and stereotypy [Sakata and Brainard 2006] and transition entropy [Scharff and Nottebohm 1991].\n",
    "\n",
    "Date: 13/10/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas\n",
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set directory\n",
    "os.chdir('D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\Trans_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pandas.read_csv('BF_b36p24_transition_probability.csv', header=None)\n",
    "df = file.to_numpy()\n",
    "\n",
    "#Drop the row and column labels, just keep the numeric values\n",
    "trans_prob = file.iloc[1:, 1:]\n",
    "trans_prob = np.array(trans_prob)\n",
    "trans_prob = trans_prob.astype(float)\n",
    "\n",
    "#Get the set of unique syllables for the individual with their own index (so convert array to list)\n",
    "uniq_syl = file.iloc[0].to_numpy()\n",
    "uniq_syl = np.delete(uniq_syl, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 30.0 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "#SEQUENCE LINEARITY\n",
    "#Number of unique syllables\n",
    "n_syl = len(uniq_syl)\n",
    "\n",
    "#To get the number of unique transitions, create an array with 1 whenever trans_prob > 0\n",
    "#and get the sum of the array\n",
    "trans_num = np.zeros_like(trans_prob)\n",
    "trans_num[trans_prob > 0] = 1\n",
    "n_trans = sum(map(sum, trans_num))\n",
    "\n",
    "s_lin = n_syl/n_trans\n",
    "\n",
    "print(n_syl, n_trans, s_lin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.680000000000001 6.970000000000001 0.6714490674318508\n"
     ]
    }
   ],
   "source": [
    "#SEQUENCE CONSISTENCY\n",
    "#\"The typical transition type for each note is operationally defined as the one most frequently encountered \n",
    "#(for introductory notes, the two most frequently encountered).\"\n",
    "\n",
    "#numerator - sum of typical transitions\n",
    "typ_trans = np.max(trans_prob, axis = 1)\n",
    "typ_sum = sum(typ_trans)\n",
    "\n",
    "#denominator - sum of all transitions\n",
    "trans_sum = sum(map(sum, trans_prob))\n",
    "\n",
    "s_con = typ_sum/trans_sum\n",
    "\n",
    "print(typ_sum, trans_sum, s_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4690578670492588"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SEQUENCE STEREOTYPY\n",
    "\n",
    "s_stereo = (s_lin + s_con)/2\n",
    "s_stereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VASUDH~1\\AppData\\Local\\Temp/ipykernel_8680/1943322041.py:9: RuntimeWarning: divide by zero encountered in log2\n",
      "  trans_entropy[i, j] = -trans_entropy[i, j] * np.log2(trans_entropy[i, j])\n",
      "C:\\Users\\VASUDH~1\\AppData\\Local\\Temp/ipykernel_8680/1943322041.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  trans_entropy[i, j] = -trans_entropy[i, j] * np.log2(trans_entropy[i, j])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.866267142040055"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TRANSITION ENTROPY\n",
    "from math import nan\n",
    "\n",
    "\n",
    "trans_entropy = trans_prob\n",
    "\n",
    "for i in range(len(trans_entropy)):\n",
    "    for j in range(len(trans_entropy)):\n",
    "        trans_entropy[i, j] = -trans_entropy[i, j] * np.log2(trans_entropy[i, j])\n",
    "\n",
    "trans_entropy[np.isnan(trans_entropy)] = 0\n",
    "transition_entropy = sum(map(sum, trans_entropy))\n",
    "\n",
    "transition_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "008563563e781916d6359c24295d5508987d9d4a8f497f916ed83e23a440f2f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
