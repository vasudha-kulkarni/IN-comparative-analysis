{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code to differentiate the differences statistically.\n",
    "\n",
    "13/11/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\Quant\\\\Updated_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions for ANOVA - \n",
    "1. Measurements are made randomly from a population\n",
    "2. Variable is normally distributed in each of the populations\n",
    "3. Variance is the same in all k populations\n",
    "\n",
    "BUT: ANOVA is robust to departures from the assumption of equal variance (Ch 15, Whitlock and Schuster), but only if samples are all large, about the same size and no more than 10-fold difference among variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normality test for ANOVA - scipy.stats.shapiro(x)\n",
    "\n",
    "Shapiro Wilk test is suited for smaller sample size < 50. If something is not normally distributed, then either the data has to be transformed, or we've to use a test that doesn't assume normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normally distrbuted: BCC\n",
      "Variance = 3.2047312444728235\n",
      "Normally distrbuted: BF\n",
      "Variance = 4.97151076932196\n",
      "Normally distrbuted: JF\n",
      "Variance = 3.0103820451192767\n",
      "Normally distrbuted: ZF\n",
      "Variance = 1.2946812732115414\n"
     ]
    }
   ],
   "source": [
    "#data = pd.read_csv(\"01. Song_quantifiers.csv\")\n",
    "data = pd.read_csv(\"02. Syll_quantifiers.csv\")\n",
    "\n",
    "#Subset data and keep the parameter\n",
    "df1 = data[['Bird name', 'Species', 'Song duration']] #c1\n",
    "\n",
    "species = ['BCC', 'BF', 'JF', 'ZF']\n",
    "\n",
    "for i in range(len(species)):\n",
    "    df2 = df1.loc[df1['Species'] == species[i]]\n",
    "    df3 = df2['Song duration'] #c2\n",
    "    k2, p = stats.shapiro(df3)\n",
    "    alpha = 0.05\n",
    "    if p < alpha:\n",
    "        print(f'The values of this species are NOT normally distrbuted: {species[i]}')\n",
    "    else:\n",
    "        print(f'Normally distrbuted: {species[i]}')\n",
    "    std_dev = np.std(df3)\n",
    "    var = std_dev**2\n",
    "    print(f'Variance = {var}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=25.739667623693474, pvalue=2.1992000940848636e-07)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = df1.loc[df1['Species'] == 'BCC']\n",
    "a2 = a1['Song duration'].to_list()\n",
    "\n",
    "b1 = df1.loc[df1['Species'] == 'BF']\n",
    "b2 = b1['Song duration'].to_list()\n",
    "\n",
    "c1 = df1.loc[df1['Species'] == 'JF']\n",
    "c2 = c1['Song duration'].to_list()\n",
    "\n",
    "d1 = df1.loc[df1['Species'] == 'ZF']\n",
    "d2 = d1['Song duration'].to_list()\n",
    "\n",
    "stats.f_oneway(a2, b2, c2, d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kruskal-Wallis test - non-parametric alternative for ANOVA (similar to Mann Whitney U test, but for multiple groups). Assumptions - \n",
    "1. All group saples were drawn randomly\n",
    "2. Distribution of variable must have the same shape in every population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=10.895726495726493, pvalue=0.012303293433544842)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.kruskal(a2, b2, c2, d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If ANOVA p-value is significant, it tells us one group is significantly different than the others, but it doesn't really tell us which one it is. So, we do a post hoc Tukey-Kramer test (Tukey for equal sample size, T-K for unequal), which allows us to make pairwise comparisons.\n",
    "\n",
    "#90% sure that 'pairwise_tukeyhsd' is the same as Tukey-Kramer test, it's not explicitly mentioned in the documentation.\n",
    "\n",
    "Alaternative - use Scheffe's method for a post hoc test - applicable in all conditions, but more conservative than Tukey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      "group1 group2 meandiff p-adj   lower    upper  reject\n",
      "-----------------------------------------------------\n",
      "   BCC     BF    8.648  0.001   5.7075 11.5885   True\n",
      "   BCC     JF   3.5754 0.0134   0.6348  6.5159   True\n",
      "   BCC     ZF    0.843  0.781   -1.736   3.422  False\n",
      "    BF     JF  -5.0727 0.0015  -8.3349 -1.8104   True\n",
      "    BF     ZF   -7.805  0.001 -10.7455 -4.8645   True\n",
      "    JF     ZF  -2.7323 0.0749  -5.6729  0.2082  False\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'values' : a2 + b2 + c2 + d2,\n",
    "    'label' : np.repeat(['BCC', 'BF', 'JF', 'ZF'], repeats=[len(a2), len(b2), len(c2), len(d2)])\n",
    "    })\n",
    "\n",
    "#Not valid right now, because variance is too much and sample size is unequal\n",
    "tuk = pairwise_tukeyhsd(endog=df['values'], groups=df['label'], alpha=0.05)\n",
    "print(tuk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df, CI):\n",
    "    \n",
    "    alpha = 1-CI/100\n",
    "    \n",
    "    if len(df.index)<2: df = df.rename(columns = {\"p-unc\" : \"pval\"})    #the pval column  has different names based on test and numerosity\n",
    "    else: df = df.rename(columns = {\"p-corr\" : \"pval\"})\n",
    "    \n",
    "    df.rename({'A': 'group1', 'B': 'group2', \"pval\":\"p-adj\"}, axis=\"columns\", inplace=True)\n",
    "    \n",
    "    '''\n",
    "    Creates a compact letter display. This creates a dataframe consisting of\n",
    "    2 columns, a column containing the treatment groups and a column containing\n",
    "    the letters that have been assigned to the treatment groups. These letters\n",
    "    are part of what's called the compact letter display. Treatment groups that\n",
    "    share at least 1 letter are similar to each other, while treatment groups\n",
    "    that don't share any letters are significantly different from each other.\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas dataframe\n",
    "        Pandas dataframe containing raw Tukey test results from statsmodels.\n",
    "    alpha : float\n",
    "        The alpha value. The default is 0.05.\n",
    "    Returns\n",
    "    -------\n",
    "    A dataframe representing the compact letter display, created from the Tukey\n",
    "    test results.\n",
    "    '''\n",
    "    df[\"p-adj\"] = df[\"p-adj\"].astype(float)\n",
    "\n",
    "    # Creating a list of the different treatment groups from Tukey's\n",
    "    group1 = set(df.group1.tolist())  # Dropping duplicates by creating a set\n",
    "    group2 = set(df.group2.tolist())  # Dropping duplicates by creating a set\n",
    "    groupSet = group1 | group2  # Set operation that creates a union of 2 sets\n",
    "    groups = sorted(list(groupSet))\n",
    "\n",
    "    # Creating lists of letters that will be assigned to treatment groups\n",
    "    letters = list(string.ascii_lowercase+string.digits)[:len(groups)]\n",
    "    cldgroups = letters\n",
    "\n",
    "    # the following algoritm is a simplification of the classical cld,\n",
    "\n",
    "    cld = pd.DataFrame(list(zip(groups, letters, cldgroups)))\n",
    "    cld[3]=\"\"\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        if df[\"p-adj\"][row[0]] > (alpha):\n",
    "            cld.iat[groups.index(df[\"group1\"][row[0]]), 2] += cld.iat[groups.index(df[\"group2\"][row[0]]), 1]\n",
    "            cld.iat[groups.index(df[\"group2\"][row[0]]), 2] += cld.iat[groups.index(df[\"group1\"][row[0]]), 1]\n",
    "            \n",
    "        if df[\"p-adj\"][row[0]] < (alpha):\n",
    "                cld.iat[groups.index(df[\"group1\"][row[0]]), 3] +=  cld.iat[groups.index(df[\"group2\"][row[0]]), 1]\n",
    "                cld.iat[groups.index(df[\"group2\"][row[0]]), 3] +=  cld.iat[groups.index(df[\"group1\"][row[0]]), 1]\n",
    "\n",
    "    cld[2] = cld[2].apply(lambda x: \"\".join(sorted(x)))\n",
    "    cld[3] = cld[3].apply(lambda x: \"\".join(sorted(x)))\n",
    "    cld.rename(columns={0: \"groups\"}, inplace=True)\n",
    "\n",
    "    # this part will reassign the final name to the group\n",
    "    # for sure there are more elegant ways of doing this\n",
    "    cld[\"labels\"] = \"\"\n",
    "    letters = list(string.ascii_lowercase)\n",
    "    unique = []\n",
    "    for item in cld[2]:\n",
    "\n",
    "        for fitem in cld[\"labels\"].unique():\n",
    "            for c in range(0, len(fitem)):\n",
    "                if not set(unique).issuperset(set(fitem[c])):\n",
    "                    unique.append(fitem[c])\n",
    "        g = len(unique)\n",
    "\n",
    "        for kitem in cld[1]:\n",
    "            if kitem in item:\n",
    "                #Checking if there are forbidden pairing (proposition of solution to the imperfect script)                \n",
    "                forbidden = set()\n",
    "                for row in cld.itertuples():\n",
    "                    if letters[g] in row[5]:\n",
    "                        forbidden |= set(row[4])\n",
    "                if kitem in forbidden:\n",
    "                    g=len(unique)+1\n",
    "               \n",
    "                if cld[\"labels\"].loc[cld[1] == kitem].iloc[0] == \"\":\n",
    "                   cld[\"labels\"].loc[cld[1] == kitem] += letters[g] \n",
    "               \n",
    "                # Checking if columns 1 & 2 of cld share at least 1 letter\n",
    "                if len(set(cld[\"labels\"].loc[cld[1] == kitem].iloc[0]).intersection(cld.loc[cld[2] == item, \"labels\"].iloc[0])) <= 0:\n",
    "                    if letters[g] not in list(cld[\"labels\"].loc[cld[1] == kitem].iloc[0]):\n",
    "                        cld[\"labels\"].loc[cld[1] == kitem] += letters[g]\n",
    "                    if letters[g] not in list(cld[\"labels\"].loc[cld[2] == item].iloc[0]):\n",
    "                        cld[\"labels\"].loc[cld[2] == item] += letters[g]\n",
    "\n",
    "    cld = cld.sort_values(\"labels\")\n",
    "    cld.drop(columns=[1, 2, 3], inplace=True)\n",
    "    print(cld)\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    return(cld)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "008563563e781916d6359c24295d5508987d9d4a8f497f916ed83e23a440f2f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
