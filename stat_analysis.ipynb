{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code to differentiate the differences statistically.\n",
    "\n",
    "13/11/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import scikit_posthocs as sp\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\Quant\\\\Updated_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions for ANOVA - \n",
    "1. Measurements are made randomly from a population\n",
    "2. Variable is normally distributed in each of the populations\n",
    "3. Variance is the same in all k populations\n",
    "\n",
    "BUT: ANOVA is robust to departures from the assumption of equal variance (Ch 15, Whitlock and Schuster), but only if samples are all large, about the same size and no more than 10-fold difference among variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normality test for ANOVA - scipy.stats.shapiro(x)\n",
    "\n",
    "Shapiro Wilk test is suited for smaller sample size < 50. If something is not normally distributed, then either the data has to be transformed, or we've to use a test that doesn't assume normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of this species are NOT normally distrbuted: BCC\n",
      "Variance = 0.03938128543132299\n",
      "The values of this species are NOT normally distrbuted: BF\n",
      "Variance = 0.02642834467120182\n",
      "The values of this species are NOT normally distrbuted: JF\n",
      "Variance = 0.08310828821324451\n",
      "The values of this species are NOT normally distrbuted: ZF\n",
      "Variance = 0.040044285982360706\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"01. Song_quantifiers.csv\")\n",
    "#data = pd.read_csv(\"02. Syll_quantifiers.csv\")\n",
    "\n",
    "#Subset data and keep the parameter\n",
    "df1 = data[['Bird name', 'Species', 'Self-transition prob']] #c1\n",
    "\n",
    "species = ['BCC', 'BF', 'JF', 'ZF']\n",
    "\n",
    "for i in range(len(species)):\n",
    "    df2 = df1.loc[df1['Species'] == species[i]]\n",
    "    df3 = df2['Self-transition prob'] #c2\n",
    "    k2, p = stats.shapiro(df3)\n",
    "    alpha = 0.05\n",
    "    if p < alpha:\n",
    "        print(f'The values of this species are NOT normally distrbuted: {species[i]}')\n",
    "    else:\n",
    "        print(f'Normally distrbuted: {species[i]}')\n",
    "    std_dev = np.std(df3)\n",
    "    var = std_dev**2\n",
    "    print(f'Variance = {var}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = df1.loc[df1['Species'] == 'BCC']\n",
    "a2 = a1['Self-transition prob'].to_list()\n",
    "\n",
    "b1 = df1.loc[df1['Species'] == 'BF']\n",
    "b2 = b1['Self-transition prob'].to_list()\n",
    "\n",
    "c1 = df1.loc[df1['Species'] == 'JF']\n",
    "c2 = c1['Self-transition prob'].to_list()\n",
    "\n",
    "d1 = df1.loc[df1['Species'] == 'ZF']\n",
    "d2 = d1['Self-transition prob'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(a2, b2, c2, d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If ANOVA p-value is significant, it tells us one group is significantly different than the others, but it doesn't really tell us which one it is. So, we do a post hoc Tukey-Kramer test (Tukey for equal sample size, T-K for unequal), which allows us to make pairwise comparisons.\n",
    "\n",
    "#90% sure that 'pairwise_tukeyhsd' is the same as Tukey-Kramer test, it's not explicitly mentioned in the documentation.\n",
    "\n",
    "Alaternative - use Scheffe's method for a post hoc test - applicable in all conditions, but more conservative than Tukey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      "group1 group2 meandiff p-adj   lower    upper  reject\n",
      "-----------------------------------------------------\n",
      "   BCC     BF    8.648  0.001   5.7075 11.5885   True\n",
      "   BCC     JF   3.5754 0.0134   0.6348  6.5159   True\n",
      "   BCC     ZF    0.843  0.781   -1.736   3.422  False\n",
      "    BF     JF  -5.0727 0.0015  -8.3349 -1.8104   True\n",
      "    BF     ZF   -7.805  0.001 -10.7455 -4.8645   True\n",
      "    JF     ZF  -2.7323 0.0749  -5.6729  0.2082  False\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'values' : a2 + b2 + c2 + d2,\n",
    "    'label' : np.repeat(['BCC', 'BF', 'JF', 'ZF'], repeats=[len(a2), len(b2), len(c2), len(d2)])\n",
    "    })\n",
    "\n",
    "#Not valid right now, because variance is too much and sample size is unequal\n",
    "tuk = pairwise_tukeyhsd(endog=df['values'], groups=df['label'], alpha=0.05)\n",
    "print(tuk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kruskal-Wallis test - non-parametric alternative for ANOVA (similar to Mann Whitney U test, but for multiple groups). But this test is less powerful for small sample sizes. Assumptions - \n",
    "1. All group saples were drawn randomly\n",
    "2. Distribution of variable must have the same shape in every population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=17.718210233145633, pvalue=0.0005028042641747661)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.kruskal(a2, b2, c2, d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunn test - this is the non-parametric post-hoc test used to do pairwise comparison after Kruskal-Wallis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          BCC        BF        JF        ZF\n",
      "BCC  1.000000  0.526943  0.000031  0.134983\n",
      "BF   0.526943  1.000000  0.004837  0.576338\n",
      "JF   0.000031  0.004837  1.000000  0.008733\n",
      "ZF   0.134983  0.576338  0.008733  1.000000\n",
      "       BCC     BF     JF     ZF\n",
      "BCC  False  False   True  False\n",
      "BF   False  False   True  False\n",
      "JF    True   True  False   True\n",
      "ZF   False  False   True  False\n"
     ]
    }
   ],
   "source": [
    "data = [a2, b2, c2, d2]\n",
    "col = ['BCC', 'BF', 'JF', 'ZF']\n",
    "\n",
    "dunn = sp.posthoc_dunn(data)\n",
    "# Doesn't give significant result, probably because of extra corrections?\n",
    "#dunn = sp.posthoc_dunn(data, p_adjust='bonferroni') \n",
    "\n",
    "dunn.columns = col\n",
    "dunn.index = col\n",
    "\n",
    "print(dunn)\n",
    "print(dunn < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signed Rank test for Amplitude, Frequency, Duration and Interval of first and fifth syllable\n",
    "\n",
    "Wilcoxon test assumes even distribution around the median i.e., no skew which is similar to the normality assumption, restricting its use.\n",
    "If normality condition is not met, simply Sign Test can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wilcoxon signed-rank test tests the null hypothesis that two related paired samples come from the same distribution. In particular, it tests whether the distribution of the differences x - y is symmetric about zero. It is a non-parametric version of the paired T-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normally distrbuted #1: BCC\n",
      "Normally distrbuted #5: BCC\n",
      "Variance #1 = 8441.236523775713 and Variance #5 = 1233.7611071954182\n",
      "Normally distrbuted #1: BF\n",
      "Normally distrbuted #5: BF\n",
      "Variance #1 = 20948.311494024667 and Variance #5 = 732.9232362166167\n",
      "Normally distrbuted #1: JF\n",
      "Normally distrbuted #5: JF\n",
      "Variance #1 = 18000.229682536414 and Variance #5 = 9645.689852715213\n",
      "Normally distrbuted #1: ZF\n",
      "Normally distrbuted #5: ZF\n",
      "Variance #1 = 13470.565616813237 and Variance #5 = 291.04630716036627\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"06. Avg internote interval values.csv\") #c1\n",
    "\n",
    "df1 = data[['Bird name', 'Species', '#1', '#5']]\n",
    "\n",
    "species = ['BCC', 'BF', 'JF', 'ZF']\n",
    "\n",
    "for i in range(len(species)):\n",
    "    df2 = df1.loc[df1['Species'] == species[i]]\n",
    "    df3 = df2['#1']\n",
    "    k1, p1 = stats.shapiro(df3)\n",
    "    df4 = df2['#5']\n",
    "    k2, p2 = stats.shapiro(df4)\n",
    "    alpha = 0.05\n",
    "    if p1 < alpha:\n",
    "        print(f'The values of this species #1 are NOT normally distrbuted: {species[i]}')\n",
    "    else:\n",
    "        print(f'Normally distrbuted #1: {species[i]}')\n",
    "    if p2 < alpha:\n",
    "        print(f'The values of this species #5 are NOT normally distrbuted: {species[i]}')\n",
    "    else:\n",
    "        print(f'Normally distrbuted #5: {species[i]}')\n",
    "    std_dev1 = np.std(df3)\n",
    "    std_dev2 = np.std(df4)\n",
    "    var1 = std_dev1**2\n",
    "    var2 = std_dev2**2\n",
    "    print(f'Variance #1 = {var1} and Variance #5 = {var2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon test p-value for BCC is 0.0078125\n",
      "Wilcoxon test p-value for BF is 0.0625\n",
      "Wilcoxon test p-value for JF is 0.0625\n",
      "Wilcoxon test p-value for ZF is 0.0078125\n"
     ]
    }
   ],
   "source": [
    "species = ['BCC', 'BF', 'JF', 'ZF']\n",
    "\n",
    "for i in range(len(species)):\n",
    "    df2 = df1.loc[df1['Species'] == species[i]]\n",
    "    v1 = df2['#1']\n",
    "    v2 = df2['#5']\n",
    "    #'alternative' states the alternative hypothesis - \n",
    "    #for amplitude and frequency, it's 'greater', but interval it's 'less'\n",
    "    s, p = stats.wilcoxon(v2, v1, alternative='two-sided')\n",
    "    print(f'Wilcoxon test p-value for {species[i]} is {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolmogorov-Smrinov test - non-parametric goodness-of-fit test. COmpares the cumulative distribution function of two randomly drawn distributions from two populations.\n",
    "\n",
    "The null hypothesis is that the two dataset are from the same cumulative distribution function, that is, if p > 0.05, we *cannot* reject the null hypothesis => two datasaet have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"07. Start-Self Transition Prob.csv\")\n",
    "#data = pd.read_csv(\"08. IN Start-Self Transition Prob.csv\")\n",
    "\n",
    "#Subset data and keep the parameter\n",
    "df1 = data[['Bird name', 'Species', 'Beginning bout probability']] #c1\n",
    "\n",
    "species = ['BCC', 'BF', 'JF', 'ZF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = df1.loc[df1['Species'] == 'BCC']\n",
    "a2 = a1['Beginning bout probability'].to_list()\n",
    "\n",
    "b1 = df1.loc[df1['Species'] == 'BF']\n",
    "b2 = b1['Beginning bout probability'].to_list()\n",
    "\n",
    "c1 = df1.loc[df1['Species'] == 'JF']\n",
    "c2 = c1['Beginning bout probability'].to_list()\n",
    "\n",
    "d1 = df1.loc[df1['Species'] == 'ZF']\n",
    "d2 = d1['Beginning bout probability'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sp = [a2, b2, c2, d2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS test p-value between BCC and BF is 0.9062622800906234\n",
      "KS test p-value between BCC and JF is 0.3749763802750972\n",
      "KS test p-value between BCC and ZF is 0.8682487070928974\n",
      "KS test p-value between BF and BCC is 0.9062622800906234\n",
      "KS test p-value between BF and JF is 0.5241942445819909\n",
      "KS test p-value between BF and ZF is 0.8990910280700597\n",
      "KS test p-value between JF and BCC is 0.3749763802750972\n",
      "KS test p-value between JF and BF is 0.5241942445819909\n",
      "KS test p-value between JF and ZF is 0.9913585642488335\n",
      "KS test p-value between ZF and BCC is 0.8682487070928974\n",
      "KS test p-value between ZF and BF is 0.8990910280700597\n",
      "KS test p-value between ZF and JF is 0.9913585642488335\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_sp)):\n",
    "    for j in range(len(data_sp)):\n",
    "        if i != j:\n",
    "            k, p = stats.kstest(data_sp[i], data_sp[j])\n",
    "            if p < 0.05:\n",
    "                print(f'KS test significant p-value between {species[i]} and {species[j]} is {p}')\n",
    "            else:\n",
    "                print(f'KS test p-value between {species[i]} and {species[j]} is {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "kstest() missing 1 required positional argument: 'cdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\VASUDH~1\\AppData\\Local\\Temp/ipykernel_12320/1980878794.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkstest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vasudha Kulkarni\\anaconda3\\lib\\site-packages\\scipy\\_lib\\_util.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: kstest() missing 1 required positional argument: 'cdf'"
     ]
    }
   ],
   "source": [
    "k, p = stats.kstest([a2, b2, c2, d2])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anderson_ksampResult(statistic=1.9156481935815992, critical_values=array([0.49854918, 1.3236709 , 1.91577682, 2.49304213, 3.24593219,\n",
       "       3.82285604, 5.12078789]), significance_level=0.049488579867017185)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.anderson_ksamp([a2, b2, c2, d2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "008563563e781916d6359c24295d5508987d9d4a8f497f916ed83e23a440f2f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
