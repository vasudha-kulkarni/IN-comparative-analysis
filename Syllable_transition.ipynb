{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file has the code to obtain syllable transition values from Onset-Offset data, and process the file\n",
    "\n",
    "Date: 20/9/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set directory\n",
    "os.chdir('D:\\\\4th Year\\\\Semester 7\\\\BI4313 Sem Project\\\\IN-comparative-analysis\\\\IN-comparative-analysis\\\\OnsetOffsetFiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import text file as csv, choose header false and give column names manually, because they don't seem to align\n",
    "#Use 'print(data.columns)' to get the list of column names\n",
    "data = pandas.read_csv('M09.txt', sep = '\\t', header=None, names = ['FileName', 'Syll #', 'Syll Label',\n",
    "       ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "       ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "       'AmplitudeModulation', 'EntropyVariance'])\n",
    "\n",
    "#Drop the first row because column names are repeated there\n",
    "data = data.iloc[1:, :]\n",
    "\n",
    "#Convert onset, offset and syllable duration to float type\n",
    "data[' Syll Onset (ms)'] = data[' Syll Onset (ms)'].astype(float)\n",
    "data[' Syll Offset (ms)'] = data[' Syll Offset (ms)'].astype(float)\n",
    "data[' Syll Duration (sec)'] = data[' Syll Duration (sec)'].astype(float)\n",
    "#data[' Syll Offset (ms)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#t_offset = data[' Syll Offset (ms)']\n",
    "#new_row = [0, 0, 'Start', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "#for i in range(1, len(data)-1):\n",
    "#    diff = t_offset[i+1] - t_offset[i]\n",
    "#    if diff > 2000:\n",
    "#        data = pandas.DataFrame(np.insert(data.values, i, new_row, axis=0))\n",
    "\n",
    "#Problem - this code is not updating index number as it adds a 'start', so from the 2nd break onwards,\n",
    "#the 'start' label is misplaced by one row. To correct this, I'll create a list of indices and insert\n",
    "#the 'start' row using this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To add a 'start' in syllable label column after end of every bout\n",
    "\n",
    "t_offset = data[' Syll Offset (ms)']\n",
    "new_row = [0, 0, 'Start', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "index_list = []\n",
    "\n",
    "for i in range(1, len(data)-1):\n",
    "    diff = t_offset[i+1] - t_offset[i]\n",
    "    if diff > 2000:\n",
    "        index_list.append(i)\n",
    "\n",
    "#So now we have a list of indices where 'start' row should be inserted\n",
    "#Adjust the index to correct for where the row will be inserted\n",
    "for i in range(1, len(index_list)):\n",
    "    index_list[i] += 1*i\n",
    "\n",
    "#Insert the new_row at these indices\n",
    "#PS. If this doesn't make sense, remove the correction, do a simple for loop and see what happens\n",
    "for i in index_list:\n",
    "    data = pandas.DataFrame(np.insert(data.values, i, new_row, axis=0))\n",
    "\n",
    "#To confirm\n",
    "#print(data)\n",
    "#data.to_csv('M09_tp.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['FileName', 'Syll #', 'Syll Label',\n",
    "       ' Syll Onset (ms)', ' Syll Offset (ms)', ' Syll Duration (sec)', ' Mean Frequency (Hz)',\n",
    "       ' Entropy', 'Log Amplitude (dB)', 'Pitch Goodness', 'FrequencyModulation',\n",
    "       'AmplitudeModulation', 'EntropyVariance']\n",
    "\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the occurrence of number of syllables\n",
    "#And confirm that this is the same as row_sum of trans_matrix\n",
    "\n",
    "syl_n = data['Syll Label'].value_counts()\n",
    "\n",
    "#syl_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "syl = data['Syll Label']\n",
    "#print(syl)\n",
    "\n",
    "#Get the set of unique syllables for the individual with their own index (so convert array to list)\n",
    "uniq_syl = syl.unique()\n",
    "uniq_syl = uniq_syl.tolist()\n",
    "#print(uniq_syl)\n",
    "\n",
    "#Get the number of syllables to create a N x N matrix for transition\n",
    "N = len(uniq_syl)\n",
    "trans_matrix = np.array(np.zeros((N, N), dtype = int))\n",
    "\n",
    "#uniq_syl.index('a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Convert 'object' type to array to get indices\n",
    "syl = np.array(syl)\n",
    "\n",
    "#This gives the number of syllable transitions\n",
    "for i in range(len(syl)-1):\n",
    "    a = uniq_syl.index(syl[i])\n",
    "    b = uniq_syl.index(syl[i+1])\n",
    "    trans_matrix[a, b] += 1\n",
    "\n",
    "#trans_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the number of transitions by total number of occurrence of that syllable to get transition probability\n",
    "trans_matrix = (trans_matrix.T/trans_matrix.sum(axis=1)).T\n",
    "trans_matrix = np.around(trans_matrix, 2)\n",
    "\n",
    "#print(np.sum(trans_matrix[0,]))\n",
    "#print(trans_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the labels of syllables as an extra row and column\n",
    "#While doing this, it's better to replace 'start' here with 'end' so that notes don't connect back to 'start'\n",
    "syl_name = np.array(uniq_syl)\n",
    "\n",
    "trans_prob = np.concatenate([[syl_name], trans_matrix])\n",
    "#trans_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a '0' in the beginning to insert this as a column\n",
    "syl_name = np.concatenate([[0], syl_name])\n",
    "\n",
    "trans_prob = np.insert(trans_prob, 0, syl_name, axis = 1)\n",
    "#trans_prob\n",
    "\n",
    "#Convert to dataframe to save as .csv file\n",
    "transition_probability = pandas.DataFrame(trans_prob)\n",
    "transition_probability.to_csv('M09_trans_prob.csv', header = False, index = False)\n",
    "\n",
    "#There are values lesser than 0.05 that can be removed through an IF loop perhaps\n",
    "#But we can keep the values and code the diagram to not show them\n",
    "#This file contains the low-occuring syllables as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "008563563e781916d6359c24295d5508987d9d4a8f497f916ed83e23a440f2f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
